{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47ca0cb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:30.496126Z",
     "iopub.status.busy": "2023-03-13T10:10:30.495201Z",
     "iopub.status.idle": "2023-03-13T10:10:33.272740Z",
     "shell.execute_reply": "2023-03-13T10:10:33.271147Z"
    },
    "papermill": {
     "duration": 2.794847,
     "end_time": "2023-03-13T10:10:33.277050",
     "exception": false,
     "start_time": "2023-03-13T10:10:30.482203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"2\"\n",
    "os.environ[\"OMP_SCHEDULE\"]=\"STATIC\"\n",
    "os.environ[\"OMP_PROC_BIND\"]=\"CLOSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbc1018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:33.300116Z",
     "iopub.status.busy": "2023-03-13T10:10:33.298632Z",
     "iopub.status.idle": "2023-03-13T10:10:33.334604Z",
     "shell.execute_reply": "2023-03-13T10:10:33.332771Z"
    },
    "papermill": {
     "duration": 0.051126,
     "end_time": "2023-03-13T10:10:33.339089",
     "exception": false,
     "start_time": "2023-03-13T10:10:33.287963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Num-Threads to actually core count: 2\n"
     ]
    }
   ],
   "source": [
    "real_core_count = psutil.cpu_count(logical=False)\n",
    "print(\"Set Num-Threads to actually core count:\", real_core_count)\n",
    "torch.set_num_threads(real_core_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf7469e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:33.360445Z",
     "iopub.status.busy": "2023-03-13T10:10:33.359966Z",
     "iopub.status.idle": "2023-03-13T10:10:44.788976Z",
     "shell.execute_reply": "2023-03-13T10:10:44.787263Z"
    },
    "papermill": {
     "duration": 11.443113,
     "end_time": "2023-03-13T10:10:44.792448",
     "exception": false,
     "start_time": "2023-03-13T10:10:33.349335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902d1e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:44.814258Z",
     "iopub.status.busy": "2023-03-13T10:10:44.812100Z",
     "iopub.status.idle": "2023-03-13T10:10:44.823651Z",
     "shell.execute_reply": "2023-03-13T10:10:44.822494Z"
    },
    "papermill": {
     "duration": 0.025327,
     "end_time": "2023-03-13T10:10:44.826699",
     "exception": false,
     "start_time": "2023-03-13T10:10:44.801372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Configuration:\n",
    "    '''\n",
    "    Settings for Eval\n",
    "    '''\n",
    "    # Transformer\n",
    "    transformer1: str = \"/kaggle/input/mpnet-tokenizer\"  \n",
    "    checkpoint1: str =  \"/kaggle/input/destilled-jit-mpnet/mpnet_model_traced_fold_all.pth\" \n",
    "        \n",
    "    content_ids1 =      \"/kaggle/input/destilled-jit-mpnet/content_ids_fold_all.pt\"\n",
    "    content_features1 = \"/kaggle/input/destilled-jit-mpnet/content_features_fold_all.pt\"\n",
    "    content_language1 = \"/kaggle/input/destilled-jit-mpnet/content_language_fold_all.pt\"\n",
    "    \n",
    "    transformer2: str = \"/kaggle/input/labse-tokenizer\"  \n",
    "    checkpoint2: str =  \"/kaggle/input/destilled-jit-labse/labse_model_traced_fold_all.pth\" \n",
    "        \n",
    "    content_ids2 =      \"/kaggle/input/destilled-jit-labse/content_ids_fold_all.pt\"\n",
    "    content_features2 = \"/kaggle/input/destilled-jit-labse/content_features_fold_all.pt\"\n",
    "    content_language2 = \"/kaggle/input/destilled-jit-labse/content_language_fold_all.pt\"  \n",
    "                       \n",
    "    # Predict \n",
    "    max_len: int = 96          # max len of tokenized topic and content\n",
    "    batch_size: int = 8        # batch size (keep small for max performance/speed)\n",
    "    margin: float = 0.16       # dynamic threshold margin\n",
    "     \n",
    "    # Testing\n",
    "    verbose: bool = False      # show progress bar\n",
    "    speed_test: bool = False   # encode 1000 known contents for speed testing\n",
    "    output_test: bool = False  # use 100 topics instead of sample submission and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2ccdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:44.846233Z",
     "iopub.status.busy": "2023-03-13T10:10:44.845713Z",
     "iopub.status.idle": "2023-03-13T10:10:44.851020Z",
     "shell.execute_reply": "2023-03-13T10:10:44.850071Z"
    },
    "papermill": {
     "duration": 0.018019,
     "end_time": "2023-03-13T10:10:44.853562",
     "exception": false,
     "start_time": "2023-03-13T10:10:44.835543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Configuration() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7e24bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:44.874212Z",
     "iopub.status.busy": "2023-03-13T10:10:44.872814Z",
     "iopub.status.idle": "2023-03-13T10:10:44.890483Z",
     "shell.execute_reply": "2023-03-13T10:10:44.889058Z"
    },
    "papermill": {
     "duration": 0.031132,
     "end_time": "2023-03-13T10:10:44.893550",
     "exception": false,
     "start_time": "2023-03-13T10:10:44.862418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EqualDatasetEval(Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 sorted_input,\n",
    "                 pad_token_id,\n",
    "                 max_len):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input = sorted_input\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "    \n",
    "    \n",
    "    def smart_batching_collate(self, batch):\n",
    "        \n",
    "        sequences, targets, language, length = list(zip(*batch))\n",
    "        \n",
    "        # calculate real length and not use shuffle length\n",
    "\n",
    "        b_max_len = min(max(length), self.max_len)\n",
    "        \n",
    "        bs = len(sequences)\n",
    "        \n",
    "        # no memory reallocation needed if max_len and cut afterwards\n",
    "        mask = torch.zeros((bs, self.max_len), dtype=torch.float)\n",
    "        input_ids = torch.full((bs, self.max_len), self.pad_token_id, dtype=torch.long)\n",
    "        \n",
    "        for i in range(bs):\n",
    "            mask[i, :length[i]] = 1\n",
    "            input_ids[i, :length[i]] = sequences[i]\n",
    "         \n",
    "        # cut to actually longest in batch    \n",
    "        return input_ids[:, :b_max_len], mask[:, :b_max_len], targets, language\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sort_input(text, names, language, tokenizers, max_len):\n",
    "    \n",
    "    t0 = time.time()\n",
    "     \n",
    "    print('Tokenizing {:,} training samples...'.format(len(text)))\n",
    "\n",
    "    update_interval = len(text) // 10 + 1\n",
    "\n",
    "    input_ids = []\n",
    "    length = []\n",
    "    for t in text:\n",
    "        if ((len(input_ids) % update_interval) == 0):\n",
    "            print('  Tokenized {:,} samples.'.format(len(input_ids)))\n",
    "\n",
    "        input_id = tokenizers.encode(\n",
    "            text=t,           \n",
    "            add_special_tokens=True, \n",
    "            max_length=max_len,  \n",
    "            truncation=True,     \n",
    "            padding=False,\n",
    "            return_tensors='pt'\n",
    "        )   \n",
    "\n",
    "        input_id = input_id.squeeze()                               \n",
    "        input_ids.append(input_id)\n",
    "        length.append(len(input_id))\n",
    "\n",
    "    print('DONE.')\n",
    "    print('{:>10,} samples'.format(len(input_ids)))\n",
    "\n",
    "\n",
    "    sorted_input = sorted(zip(input_ids, names, language, length), key=lambda x: x[-1], reverse=True)\n",
    "    print('Longest sample:', len(sorted_input[0][0]))\n",
    "    print('Shortest sample:', len(sorted_input[-1][0]))\n",
    "        \n",
    "    t1 = time.time()\n",
    "    print(f\"Time: {t1-t0:.3f} sec\")\n",
    "    \n",
    "    return sorted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a5ee23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:44.914513Z",
     "iopub.status.busy": "2023-03-13T10:10:44.913653Z",
     "iopub.status.idle": "2023-03-13T10:10:44.923539Z",
     "shell.execute_reply": "2023-03-13T10:10:44.922192Z"
    },
    "papermill": {
     "duration": 0.024051,
     "end_time": "2023-03-13T10:10:44.926762",
     "exception": false,
     "start_time": "2023-03-13T10:10:44.902711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(config, model, dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if config.verbose:\n",
    "        bar = tqdm(dataloader, total=len(dataloader))\n",
    "    else:\n",
    "        bar = dataloader\n",
    "        \n",
    "    features_list = []\n",
    "    ids_list = []\n",
    "    language_list = []\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for ids, mask, text_id, language in bar:\n",
    "            \n",
    "            ids_list.extend(text_id)\n",
    "            \n",
    "            language_list.extend(language)\n",
    "        \n",
    "            feature = model(ids, mask)\n",
    "\n",
    "            feature = F.normalize(feature, dim=-1)\n",
    "\n",
    "            features_list.append(feature)\n",
    "    \n",
    "    if config.verbose:\n",
    "        bar.close()\n",
    "              \n",
    "    features = torch.cat(features_list, dim=0) \n",
    "    \n",
    "    ids_list = np.array(ids_list)\n",
    "    language_list = np.array(language_list)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Time for feature extraction: {t1-t0:.3f} sec\")\n",
    "          \n",
    "    return features, ids_list, language_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d13194c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:44.947409Z",
     "iopub.status.busy": "2023-03-13T10:10:44.946870Z",
     "iopub.status.idle": "2023-03-13T10:10:44.955213Z",
     "shell.execute_reply": "2023-03-13T10:10:44.954060Z"
    },
    "papermill": {
     "duration": 0.02121,
     "end_time": "2023-03-13T10:10:44.957912",
     "exception": false,
     "start_time": "2023-03-13T10:10:44.936702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    x = str(x)\n",
    "    if x != \"\" and len(x) > 1:\n",
    "        x = x.strip().strip('\\t').strip('\\n')\n",
    "    return x\n",
    "    \n",
    "def clean_and_cut(x):\n",
    "    x = str(x)\n",
    "    if x != \"\" and len(x) > 1:\n",
    "        x = x.strip().strip('\\t').strip('\\n').replace(\"î€‰\", \"\")\n",
    "        x = re.sub(r'http\\S+', '', x)\n",
    "        x = \" \".join(x.split(\" \")[:32])[:256]\n",
    "              \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7425b197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:44.978261Z",
     "iopub.status.busy": "2023-03-13T10:10:44.977203Z",
     "iopub.status.idle": "2023-03-13T10:10:47.629200Z",
     "shell.execute_reply": "2023-03-13T10:10:47.627791Z"
    },
    "papermill": {
     "duration": 2.666656,
     "end_time": "2023-03-13T10:10:47.633471",
     "exception": false,
     "start_time": "2023-03-13T10:10:44.966815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/sample_submission.csv\")\n",
    "df_topics = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/topics.csv\").fillna({\"title\": \"\", \"description\": \"\"})\n",
    "\n",
    "topic2language = dict(zip(df_topics[\"id\"], df_topics[\"language\"]))\n",
    "\n",
    "df_sample_submission[\"language\"] = df_sample_submission[\"topic_id\"].map(lambda x : topic2language.get(x, \"unk\"))\n",
    "\n",
    "df_topics = df_topics.replace(to_replace= r'\\r\\n', value= ' ', regex=True)\n",
    "df_topics = df_topics.replace(to_replace= r'\\n', value= ' ', regex=True)\n",
    "\n",
    "df_topics[\"title\"] = df_topics[\"title\"].map(clean)\n",
    "df_topics[\"description\"] = df_topics[\"description\"].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9cb6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:47.659844Z",
     "iopub.status.busy": "2023-03-13T10:10:47.659339Z",
     "iopub.status.idle": "2023-03-13T10:10:47.675671Z",
     "shell.execute_reply": "2023-03-13T10:10:47.674280Z"
    },
    "papermill": {
     "duration": 0.031745,
     "end_time": "2023-03-13T10:10:47.678434",
     "exception": false,
     "start_time": "2023-03-13T10:10:47.646689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Topic:\n",
    "    def __init__(self, topic_id):\n",
    "        self.id = topic_id\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def parent(self):\n",
    "        parent_id = df_topics.loc[self.id].parent\n",
    "        if pd.isna(parent_id):\n",
    "            return None\n",
    "        else:\n",
    "            return Topic(parent_id)\n",
    "\n",
    "    @property\n",
    "    def ancestors(self):\n",
    "        ancestors = []\n",
    "        parent = self.parent\n",
    "        while parent is not None:\n",
    "            ancestors.append(parent)\n",
    "            parent = parent.parent\n",
    "        return ancestors\n",
    "\n",
    "    @property\n",
    "    def siblings(self):\n",
    "        if not self.parent:\n",
    "            return []\n",
    "        else:\n",
    "            return [topic for topic in self.parent.children if topic != self]\n",
    "\n",
    "    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n",
    "        ancestors = self.ancestors\n",
    "        if include_self:\n",
    "            ancestors = [self] + ancestors\n",
    "        if not include_root:\n",
    "            ancestors = ancestors[:-1]\n",
    "        #return separator.join(reversed([a.title for a in ancestors]))\n",
    "        return separator.join([a.title for a in ancestors])\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return [Topic(child_id) for child_id in df_topics[df_topics.parent == self.id].index]\n",
    "\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Topic):\n",
    "            return False\n",
    "        return self.id == other.id\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return df_topics.loc[self.id][name]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a90793b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:47.701490Z",
     "iopub.status.busy": "2023-03-13T10:10:47.698012Z",
     "iopub.status.idle": "2023-03-13T10:10:47.753484Z",
     "shell.execute_reply": "2023-03-13T10:10:47.751892Z"
    },
    "papermill": {
     "duration": 0.069727,
     "end_time": "2023-03-13T10:10:47.757152",
     "exception": false,
     "start_time": "2023-03-13T10:10:47.687425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.output_test:\n",
    "    df_correlations = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/correlations.csv\")\n",
    "    topic_test = df_correlations[\"topic_id\"].values[:100]\n",
    "    df_correlations[\"language\"] = df_correlations[\"topic_id\"].map(lambda x : topic2language.get(x, \"unk\"))\n",
    "    language_t = df_correlations[\"language\"].values[:100].tolist()\n",
    "else:\n",
    "    topic_test = df_sample_submission[\"topic_id\"].values \n",
    "    language_t = df_sample_submission[\"language\"].values.tolist()\n",
    "    \n",
    "df_topics.set_index(\"id\", inplace=True) \n",
    "\n",
    "topic2string = {}\n",
    "\n",
    "if config.verbose:\n",
    "    bar = tqdm(topic_test, total=len(topic_test))\n",
    "else:\n",
    "    bar = topic_test\n",
    "\n",
    "for t in bar:\n",
    "    to = Topic(t)\n",
    "    string = \"{} # {}\".format(to.get_breadcrumbs(separator=\" # \", include_self=True), to.description)\n",
    "    topic2string[t] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb887c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:47.777770Z",
     "iopub.status.busy": "2023-03-13T10:10:47.776886Z",
     "iopub.status.idle": "2023-03-13T10:10:47.783908Z",
     "shell.execute_reply": "2023-03-13T10:10:47.782728Z"
    },
    "papermill": {
     "duration": 0.020945,
     "end_time": "2023-03-13T10:10:47.786953",
     "exception": false,
     "start_time": "2023-03-13T10:10:47.766008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids_t = topic_test.tolist()\n",
    "\n",
    "text_t = []\n",
    "for t in ids_t:\n",
    "    text_t.append(topic2string[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6245d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:10:47.809164Z",
     "iopub.status.busy": "2023-03-13T10:10:47.808150Z",
     "iopub.status.idle": "2023-03-13T10:11:12.655970Z",
     "shell.execute_reply": "2023-03-13T10:11:12.654455Z"
    },
    "papermill": {
     "duration": 24.86301,
     "end_time": "2023-03-13T10:11:12.659605",
     "exception": false,
     "start_time": "2023-03-13T10:10:47.796595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_content = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/content.csv\").fillna({\"title\": \"\", \"description\": \"\", \"text\": \"\"}).set_index(\"id\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb96e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:12.680205Z",
     "iopub.status.busy": "2023-03-13T10:11:12.679683Z",
     "iopub.status.idle": "2023-03-13T10:11:21.846293Z",
     "shell.execute_reply": "2023-03-13T10:11:21.844565Z"
    },
    "papermill": {
     "duration": 9.180953,
     "end_time": "2023-03-13T10:11:21.849566",
     "exception": false,
     "start_time": "2023-03-13T10:11:12.668613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess: Same order of Content1 and Content2\n",
      "Sucess: Same order of Content Language 1 and Content Language 2\n"
     ]
    }
   ],
   "source": [
    "content_ids1 = np.array(torch.load(config.content_ids1))\n",
    "content_language1 = np.array(torch.load(config.content_language1))\n",
    "content_features1 = torch.load(config.content_features1)\n",
    "\n",
    "content_ids2 = np.array(torch.load(config.content_ids2))\n",
    "content_language2 = np.array(torch.load(config.content_language2))\n",
    "content_features2 = torch.load(config.content_features2)\n",
    "\n",
    "content_id_to_index = dict(zip(content_ids2, np.arange(len(content_ids2))))  \n",
    "\n",
    "reorder = []\n",
    "\n",
    "for idx in content_ids1:\n",
    "    reorder.append(content_id_to_index[idx])\n",
    "    \n",
    "reorder = np.array(reorder)\n",
    "\n",
    "content_ids2 = content_ids2[reorder]\n",
    "content_language2 = content_language2[reorder]\n",
    "content_features2 = content_features2[reorder]\n",
    "\n",
    "if (content_ids1 == content_ids2).sum() == len(content_ids1):\n",
    "    print(\"Sucess: Same order of Content1 and Content2\")\n",
    "else:\n",
    "    print(\"Error: Content1 and Conten2 have not the same order!!!\")\n",
    "    \n",
    "    \n",
    "if (content_language1 == content_language2).sum() == len(content_language1):\n",
    "    print(\"Sucess: Same order of Content Language 1 and Content Language 2\")\n",
    "else:\n",
    "    print(\"Error: Content Language 1 and Content Language 2 have not the same order!!!\")\n",
    "     \n",
    "content_ids = content_ids1\n",
    "content_language = content_language1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63d0985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:21.873379Z",
     "iopub.status.busy": "2023-03-13T10:11:21.871970Z",
     "iopub.status.idle": "2023-03-13T10:11:22.402860Z",
     "shell.execute_reply": "2023-03-13T10:11:22.400552Z"
    },
    "papermill": {
     "duration": 0.548251,
     "end_time": "2023-03-13T10:11:22.407107",
     "exception": false,
     "start_time": "2023-03-13T10:11:21.858856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght all content:     154047\n",
      "Lenght known content:   154047\n",
      "Lenght unknown content: 0\n"
     ]
    }
   ],
   "source": [
    "# For speed Test on Content\n",
    "if config.speed_test:\n",
    "    known_content = set(content_ids[:-1000])\n",
    "else:\n",
    "    known_content = set(content_ids)\n",
    "      \n",
    "df_content[\"known\"] = df_content.index.map(lambda x : x in known_content)\n",
    "\n",
    "unknown_content_df = df_content[df_content[\"known\"] == False].copy()\n",
    "known_content_df = df_content[df_content[\"known\"] == True]\n",
    "\n",
    "print(\"Lenght all content:    \", len(df_content))\n",
    "print(\"Lenght known content:  \", len(known_content_df))\n",
    "print(\"Lenght unknown content:\", len(unknown_content_df))\n",
    "\n",
    "known_content_ids =  set(known_content_df.index)\n",
    "\n",
    "selector = []\n",
    "\n",
    "for i, c in enumerate(content_ids):\n",
    "\n",
    "    if c in known_content_ids:\n",
    "        selector.append(True)\n",
    "    else:\n",
    "        selector.append(False)\n",
    "        \n",
    "selector = np.array(selector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7759c4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:22.428926Z",
     "iopub.status.busy": "2023-03-13T10:11:22.427871Z",
     "iopub.status.idle": "2023-03-13T10:11:23.086693Z",
     "shell.execute_reply": "2023-03-13T10:11:23.084842Z"
    },
    "papermill": {
     "duration": 0.674118,
     "end_time": "2023-03-13T10:11:23.090731",
     "exception": false,
     "start_time": "2023-03-13T10:11:22.416613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of known content features:\n",
      "Before selection: 154047\n",
      "After selection:  154047\n"
     ]
    }
   ],
   "source": [
    "content_ids_k = content_ids[selector]\n",
    "content_language_k = content_language[selector]\n",
    "\n",
    "content_features1_k = content_features1[selector]\n",
    "content_features2_k = content_features2[selector]\n",
    "\n",
    "print(\"Length of known content features:\")\n",
    "print(f\"Before selection: {len(content_ids)}\")\n",
    "print(f\"After selection:  {len(content_ids_k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cac0d6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:23.111892Z",
     "iopub.status.busy": "2023-03-13T10:11:23.111435Z",
     "iopub.status.idle": "2023-03-13T10:11:23.130399Z",
     "shell.execute_reply": "2023-03-13T10:11:23.128327Z"
    },
    "papermill": {
     "duration": 0.033757,
     "end_time": "2023-03-13T10:11:23.134707",
     "exception": false,
     "start_time": "2023-03-13T10:11:23.100950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of unknown content to process: 0\n"
     ]
    }
   ],
   "source": [
    "# New Content\n",
    "unknown_content_df = unknown_content_df.replace(to_replace= r'\\r\\n', value= ' ', regex=True)\n",
    "unknown_content_df = unknown_content_df.replace(to_replace= r'\\n', value= ' ', regex=True)\n",
    "\n",
    "unknown_content_df[\"title\"] = unknown_content_df[\"title\"].map(clean)\n",
    "unknown_content_df[\"description\"] = unknown_content_df[\"description\"].map(clean)\n",
    "unknown_content_df[\"text\"] = unknown_content_df[\"text\"].map(clean_and_cut)\n",
    "\n",
    "unknown_content_df[\"text_cut\"] = unknown_content_df[\"text\"].map(lambda x : \" \".join(x.split(\" \")[:32]))\n",
    "unknown_content_df[\"input\"] = unknown_content_df[\"title\"] + \" # \" + unknown_content_df[\"description\"] + \" # \" +  unknown_content_df[\"text_cut\"]\n",
    "\n",
    "text_c = unknown_content_df[\"input\"].values.tolist()\n",
    "ids_c = unknown_content_df.index.tolist()\n",
    "language_c = unknown_content_df[\"language\"].values.tolist()\n",
    "\n",
    "print(f\"Lenght of unknown content to process: {len(text_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d8d0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:23.154963Z",
     "iopub.status.busy": "2023-03-13T10:11:23.154511Z",
     "iopub.status.idle": "2023-03-13T10:11:25.595612Z",
     "shell.execute_reply": "2023-03-13T10:11:25.593909Z"
    },
    "papermill": {
     "duration": 2.455101,
     "end_time": "2023-03-13T10:11:25.599124",
     "exception": false,
     "start_time": "2023-03-13T10:11:23.144023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 5 training samples...\n",
      "  Tokenized 0 samples.\n",
      "  Tokenized 1 samples.\n",
      "  Tokenized 2 samples.\n",
      "  Tokenized 3 samples.\n",
      "  Tokenized 4 samples.\n",
      "DONE.\n",
      "         5 samples\n",
      "Longest sample: 96\n",
      "Shortest sample: 25\n",
      "Time: 0.010 sec\n",
      "Tokenizing 5 training samples...\n",
      "  Tokenized 0 samples.\n",
      "  Tokenized 1 samples.\n",
      "  Tokenized 2 samples.\n",
      "  Tokenized 3 samples.\n",
      "  Tokenized 4 samples.\n",
      "DONE.\n",
      "         5 samples\n",
      "Longest sample: 96\n",
      "Shortest sample: 20\n",
      "Time: 0.004 sec\n"
     ]
    }
   ],
   "source": [
    "tokenizer1 = AutoTokenizer.from_pretrained(config.transformer1)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(config.transformer2)\n",
    "\n",
    "sorted_topics1 = sort_input(text_t, ids_t, language_t, tokenizer1, config.max_len)\n",
    "sorted_topics2 = sort_input(text_t, ids_t, language_t, tokenizer2, config.max_len)\n",
    "\n",
    "if len(text_c) > 0:\n",
    "    sorted_content1 = sort_input(text_c, ids_c, language_c, tokenizer1, config.max_len)\n",
    "    sorted_content2 = sort_input(text_c, ids_c, language_c, tokenizer2, config.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e38c7e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:25.619893Z",
     "iopub.status.busy": "2023-03-13T10:11:25.619407Z",
     "iopub.status.idle": "2023-03-13T10:11:36.780547Z",
     "shell.execute_reply": "2023-03-13T10:11:36.779068Z"
    },
    "papermill": {
     "duration": 11.174819,
     "end_time": "2023-03-13T10:11:36.783439",
     "exception": false,
     "start_time": "2023-03-13T10:11:25.608620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------[Model: /kaggle/input/mpnet-tokenizer]--------------------\n",
      "Time for feature extraction: 0.688 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n{}[Model: {}]{}\".format(20*\"-\", config.transformer1, 20*\"-\"))\n",
    "model = torch.jit.load(config.checkpoint1)\n",
    "model.eval()\n",
    "              \n",
    "val_dataset_topic = EqualDatasetEval(sorted_topics1,\n",
    "                                     pad_token_id = tokenizer1.pad_token_id,\n",
    "                                     max_len=config.max_len)\n",
    "\n",
    "\n",
    "val_loader_topic = DataLoader(dataset=val_dataset_topic, \n",
    "                              batch_size=config.batch_size, \n",
    "                              shuffle=False,\n",
    "                              collate_fn=val_dataset_topic.smart_batching_collate\n",
    "                              )\n",
    "\n",
    "topic_features1, topic_ids1, topic_language1 = predict(config, model, val_loader_topic)\n",
    "\n",
    "    \n",
    "if len(text_c) > 0:\n",
    "\n",
    "    val_dataset_content = EqualDatasetEval(sorted_content1,\n",
    "                                           pad_token_id = tokenizer1.pad_token_id,\n",
    "                                           max_len=config.max_len)\n",
    "\n",
    "\n",
    "    val_loader_content = DataLoader(dataset=val_dataset_content, \n",
    "                                    batch_size=config.batch_size, \n",
    "                                    shuffle=False,   \n",
    "                                    collate_fn=val_dataset_content.smart_batching_collate)\n",
    "\n",
    "    content_features1_uk, content_ids1_uk, content_language1_uk = predict(config, model, val_loader_content)  \n",
    "\n",
    "    # Add known Content\n",
    "    content_ids1 = np.concatenate([content_ids_k, content_ids1_uk])\n",
    "    content_language1 = np.concatenate([content_language_k, content_language1_uk])\n",
    "    content_features1 = torch.cat([content_features1_k, content_features1_uk], dim=0)\n",
    "\n",
    "del model, val_dataset_topic, val_loader_topic\n",
    "gc.collect()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b63507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:36.804607Z",
     "iopub.status.busy": "2023-03-13T10:11:36.804148Z",
     "iopub.status.idle": "2023-03-13T10:11:36.810458Z",
     "shell.execute_reply": "2023-03-13T10:11:36.809024Z"
    },
    "papermill": {
     "duration": 0.020155,
     "end_time": "2023-03-13T10:11:36.813358",
     "exception": false,
     "start_time": "2023-03-13T10:11:36.793203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.verbose:\n",
    "    print(topic_features1.shape)\n",
    "    print(content_features1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5160bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:36.836040Z",
     "iopub.status.busy": "2023-03-13T10:11:36.835236Z",
     "iopub.status.idle": "2023-03-13T10:11:53.124077Z",
     "shell.execute_reply": "2023-03-13T10:11:53.122302Z"
    },
    "papermill": {
     "duration": 16.304937,
     "end_time": "2023-03-13T10:11:53.127724",
     "exception": false,
     "start_time": "2023-03-13T10:11:36.822787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------[Model: /kaggle/input/labse-tokenizer]--------------------\n",
      "Time for feature extraction: 0.456 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n{}[Model: {}]{}\".format(20*\"-\", config.transformer2, 20*\"-\"))\n",
    "model = torch.jit.load(config.checkpoint2)\n",
    "model.eval()\n",
    "              \n",
    "val_dataset_topic = EqualDatasetEval(sorted_topics2,\n",
    "                                     pad_token_id = tokenizer2.pad_token_id,\n",
    "                                     max_len=config.max_len)\n",
    "\n",
    "\n",
    "val_loader_topic = DataLoader(dataset=val_dataset_topic, \n",
    "                              batch_size=config.batch_size, \n",
    "                              shuffle=False,\n",
    "                              collate_fn=val_dataset_topic.smart_batching_collate\n",
    "                              )\n",
    "\n",
    "topic_features2, topic_ids2, topic_language2 = predict(config, model, val_loader_topic)\n",
    "\n",
    "\n",
    "if (topic_ids1 == topic_ids2).sum() != len(topic_ids2):\n",
    "    \n",
    "    topic_id_to_index = dict(zip(topic_ids2, np.arange(len(topic_ids2))))  \n",
    "\n",
    "    reorder = []\n",
    "\n",
    "    for idx in topic_ids1:\n",
    "        reorder.append(topic_id_to_index[idx])\n",
    "\n",
    "    reorder = np.array(reorder)\n",
    "\n",
    "    topic_ids2 = topic_ids2[reorder]\n",
    "    topic_language2 = topic_language2[reorder]\n",
    "    topic_features2 = topic_features2[reorder]\n",
    "    \n",
    "\n",
    "    \n",
    "if len(text_c) > 0:\n",
    "\n",
    "    val_dataset_content = EqualDatasetEval(sorted_content2,\n",
    "                                           pad_token_id = tokenizer2.pad_token_id,\n",
    "                                           max_len=config.max_len)\n",
    "\n",
    "\n",
    "    val_loader_content = DataLoader(dataset=val_dataset_content, \n",
    "                                    batch_size=config.batch_size, \n",
    "                                    shuffle=False,   \n",
    "                                    collate_fn=val_dataset_content.smart_batching_collate)\n",
    "\n",
    "    content_features2_uk, content_ids2_uk, content_language2_uk = predict(config, model, val_loader_content)  \n",
    "    \n",
    "    \n",
    "\n",
    "    if (content_ids1_uk == content_ids2_uk).sum() != len(content_ids2_uk):\n",
    "    \n",
    "        content_id_to_index = dict(zip(content_ids2_uk, np.arange(len(content_ids2_uk))))  \n",
    "\n",
    "        reorder = []\n",
    "\n",
    "        for idx in content_ids1_uk:\n",
    "            reorder.append(content_id_to_index[idx])\n",
    "\n",
    "        reorder = np.array(reorder)\n",
    "\n",
    "        content_ids2_uk = content_ids2_uk[reorder]\n",
    "        content_language2_uk = content_language2_uk[reorder]\n",
    "        content_features2_uk = content_features2_uk[reorder]\n",
    "    \n",
    "    \n",
    "    # Add known Content\n",
    "    content_ids2 = np.concatenate([content_ids_k, content_ids2_uk])\n",
    "    content_language2 = np.concatenate([content_language_k, content_language2_uk])\n",
    "    content_features2 = torch.cat([content_features2_k, content_features2_uk], dim=0)\n",
    "\n",
    "del model, val_dataset_topic, val_loader_topic\n",
    "gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4acd65f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.150121Z",
     "iopub.status.busy": "2023-03-13T10:11:53.148581Z",
     "iopub.status.idle": "2023-03-13T10:11:53.154810Z",
     "shell.execute_reply": "2023-03-13T10:11:53.153406Z"
    },
    "papermill": {
     "duration": 0.020238,
     "end_time": "2023-03-13T10:11:53.157914",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.137676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.verbose:\n",
    "    print(topic_features2.shape)\n",
    "    print(content_features2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de4452a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.178849Z",
     "iopub.status.busy": "2023-03-13T10:11:53.178402Z",
     "iopub.status.idle": "2023-03-13T10:11:53.187044Z",
     "shell.execute_reply": "2023-03-13T10:11:53.185599Z"
    },
    "papermill": {
     "duration": 0.022287,
     "end_time": "2023-03-13T10:11:53.189788",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.167501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess: Same order of Content1 and Content2\n",
      "Sucess: Same order of Topic Language 1 and Topic Language 2\n"
     ]
    }
   ],
   "source": [
    "if (topic_ids1 == topic_ids2).sum() == len(topic_ids1):\n",
    "    print(\"Sucess: Same order of Content1 and Content2\")\n",
    "else:\n",
    "    print(\"Error: Topic1 and Topic2 have not the same order!!!\")\n",
    "    \n",
    "    \n",
    "if (topic_language1 == topic_language2).sum() == len(topic_language1):\n",
    "    print(\"Sucess: Same order of Topic Language 1 and Topic Language 2\")\n",
    "else:\n",
    "    print(\"Error: Topic Language 1 and Topic Language 2 have not the same order!!!\")\n",
    "    \n",
    "topic_ids = topic_ids1\n",
    "topic_language = topic_language1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af674316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.210888Z",
     "iopub.status.busy": "2023-03-13T10:11:53.210424Z",
     "iopub.status.idle": "2023-03-13T10:11:53.225920Z",
     "shell.execute_reply": "2023-03-13T10:11:53.223714Z"
    },
    "papermill": {
     "duration": 0.030744,
     "end_time": "2023-03-13T10:11:53.230064",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.199320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess: Same order of Content1 and Content2\n",
      "Sucess: Same order of Content Language 1 and Content Language 2\n"
     ]
    }
   ],
   "source": [
    "if (content_ids1 == content_ids2).sum() == len(content_ids1):\n",
    "    print(\"Sucess: Same order of Content1 and Content2\")\n",
    "else:\n",
    "    print(\"Error: Content1 and Conten2 have not the same order!!!\")\n",
    "    \n",
    "    \n",
    "if (content_language1 == content_language2).sum() == len(content_language1):\n",
    "    print(\"Sucess: Same order of Content Language 1 and Content Language 2\")\n",
    "else:\n",
    "    print(\"Error: Content Language 1 and Content Language 2 have not the same order!!!\")\n",
    "    \n",
    "content_ids = content_ids1\n",
    "content_language = content_language1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99cc6164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.252013Z",
     "iopub.status.busy": "2023-03-13T10:11:53.251436Z",
     "iopub.status.idle": "2023-03-13T10:11:53.259751Z",
     "shell.execute_reply": "2023-03-13T10:11:53.258223Z"
    },
    "papermill": {
     "duration": 0.023025,
     "end_time": "2023-03-13T10:11:53.263232",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.240207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages: ['en', 'bg', 'pt']\n"
     ]
    }
   ],
   "source": [
    "language_count = Counter(topic_language).most_common()\n",
    "language_list = [l for l, _ in language_count]\n",
    "\n",
    "print(\"Languages:\", language_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2c77ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.286474Z",
     "iopub.status.busy": "2023-03-13T10:11:53.285965Z",
     "iopub.status.idle": "2023-03-13T10:11:53.647284Z",
     "shell.execute_reply": "2023-03-13T10:11:53.645805Z"
    },
    "papermill": {
     "duration": 0.376064,
     "end_time": "2023-03-13T10:11:53.650103",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.274039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict:\n",
      "en  - (2x65939) - selected: 1\n",
      "bg  - (2x6050) - selected: 4\n",
      "pt  - (1x10435) - selected: 5\n"
     ]
    }
   ],
   "source": [
    "topic_list = []\n",
    "content_list = []\n",
    "\n",
    "\n",
    "print(\"Predict:\")\n",
    "for language in language_list:\n",
    "    \n",
    "    # Index for language\n",
    "    topic_index_language = topic_language==language\n",
    "    content_index_language = content_language==language\n",
    "    \n",
    "    # Ids\n",
    "    topic_ids_language = topic_ids[topic_index_language]\n",
    "    content_ids_language = content_ids[content_index_language]\n",
    "    \n",
    "    # Topic features\n",
    "    topic_features1_language = topic_features1[topic_index_language]\n",
    "    topic_features2_language = topic_features2[topic_index_language]\n",
    "    \n",
    "    # Content features\n",
    "    content_features1_language = content_features1[content_index_language]\n",
    "    content_features2_language = content_features2[content_index_language]\n",
    "    \n",
    "\n",
    "    if len(topic_ids_language) > 0 and len(content_ids_language) > 0:\n",
    "        \n",
    "        if topic_features1_language.dim() == 1:\n",
    "            topic_features1_language = topic_features1_language.unsqueeze(0)\n",
    "            \n",
    "        if topic_features2_language.dim() == 1:    \n",
    "            topic_features2_language = topic_features2_language.unsqueeze(0)\n",
    "\n",
    "        if content_features1_language.dim() == 1:\n",
    "            content_features1_language = content_features1_language.unsqueeze(0)\n",
    "            \n",
    "        if content_features2_language.dim() == 1:    \n",
    "            content_features2_language = content_features2_language.unsqueeze(0)\n",
    "        \n",
    "   \n",
    "        sim_matrix1 = topic_features1_language @ content_features1_language.T  \n",
    "        \n",
    "        sim_matrix2 = topic_features2_language @ content_features2_language.T \n",
    "        \n",
    "        sim_matrix = (sim_matrix1 + sim_matrix2) / 2\n",
    "        \n",
    "        selection_length = []\n",
    "        \n",
    "        for i in range(len(sim_matrix)):\n",
    "        \n",
    "            topic = topic_ids_language[i]\n",
    "\n",
    "            sim = sim_matrix[i]\n",
    "\n",
    "            th_tmp = sim.max() - config.margin * sim.max()\n",
    "\n",
    "            p_select = (sim >= th_tmp).squeeze()\n",
    "\n",
    "            c_choice = content_ids_language[p_select.numpy()]\n",
    "\n",
    "            topic_list.append(topic)\n",
    "            content_list.append(\" \".join(list(c_choice)))\n",
    "            selection_length.append(len(c_choice))\n",
    "        \n",
    "        selection_length = np.array(selection_length).mean()\n",
    "        \n",
    "        print(f\"{language.ljust(3)} - ({sim_matrix.shape[0]}x{sim_matrix.shape[1]}) - selected: {selection_length:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cdd0e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.673584Z",
     "iopub.status.busy": "2023-03-13T10:11:53.672126Z",
     "iopub.status.idle": "2023-03-13T10:11:53.686100Z",
     "shell.execute_reply": "2023-03-13T10:11:53.684873Z"
    },
    "papermill": {
     "duration": 0.028914,
     "end_time": "2023-03-13T10:11:53.689258",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.660344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"topic_id\": topic_list,\n",
    "                              \"content_ids\": content_list})\n",
    "    \n",
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c14f26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.711791Z",
     "iopub.status.busy": "2023-03-13T10:11:53.711045Z",
     "iopub.status.idle": "2023-03-13T10:11:53.717437Z",
     "shell.execute_reply": "2023-03-13T10:11:53.715793Z"
    },
    "papermill": {
     "duration": 0.021092,
     "end_time": "2023-03-13T10:11:53.720271",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.699179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.verbose:\n",
    "    display(df_submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a053e8a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.743391Z",
     "iopub.status.busy": "2023-03-13T10:11:53.742550Z",
     "iopub.status.idle": "2023-03-13T10:11:53.752024Z",
     "shell.execute_reply": "2023-03-13T10:11:53.750546Z"
    },
    "papermill": {
     "duration": 0.025004,
     "end_time": "2023-03-13T10:11:53.755239",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.730235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f2_score(gt, pd):\n",
    "\n",
    "    gt = set(gt)\n",
    "    pd = set(pd)\n",
    "\n",
    "    if len(pd) == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = len(gt.intersection(pd)) / len(pd)\n",
    "\n",
    "\n",
    "    if len(gt) == 0:\n",
    "        recall = 0.0\n",
    "    else:\n",
    "        recall = len(gt.intersection(pd)) / len(gt)\n",
    "\n",
    "\n",
    "    if (4 * precision + recall) == 0.0:\n",
    "        f2 = 0.0\n",
    "    else:\n",
    "        f2 = (5 * precision * recall) / (4 * precision + recall)\n",
    "        \n",
    "    return f2, precision, recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7a93099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T10:11:53.778258Z",
     "iopub.status.busy": "2023-03-13T10:11:53.777467Z",
     "iopub.status.idle": "2023-03-13T10:11:53.788524Z",
     "shell.execute_reply": "2023-03-13T10:11:53.787119Z"
    },
    "papermill": {
     "duration": 0.026202,
     "end_time": "2023-03-13T10:11:53.791812",
     "exception": false,
     "start_time": "2023-03-13T10:11:53.765610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.output_test:\n",
    "\n",
    "    df_correlations = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/correlations.csv\")\n",
    "\n",
    "    gt_dict = dict()\n",
    "\n",
    "    topics = df_correlations[\"topic_id\"].values\n",
    "    content = df_correlations[\"content_ids\"].values\n",
    "\n",
    "    for i in range(len(topics)):\n",
    "        content_tmp = content[i].split(\" \")\n",
    "        topic_tmp = topics[i]\n",
    "        gt_dict[topic_tmp] = content_tmp\n",
    "        \n",
    "\n",
    "    scores = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    " \n",
    "    for i, t in enumerate(topic_list):\n",
    "        \n",
    "        c = content_list[i].split(\" \")\n",
    "        \n",
    "        gt = gt_dict[t]\n",
    "\n",
    "\n",
    "        f, precision, recall = f2_score(gt, c)\n",
    "\n",
    "        scores.append(f)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "  \n",
    "    f2 = np.array(scores).mean() \n",
    "    precision = np.array(precision_list).mean()\n",
    "    recall = np.array(recall_list).mean()\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Eval Score: {:.5f} - Precision: {:.5f} - Recall: {:.3f}\".format(f2, precision, recall))\n",
    "    print(\"-\"*80)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 97.895688,
   "end_time": "2023-03-13T10:11:56.525383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-13T10:10:18.629695",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
